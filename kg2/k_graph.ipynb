{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8899e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohit/opt/anaconda3/envs/exp_pytorch_only/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb371f76f50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "np.random.seed(234)\n",
    "torch.manual_seed(234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02c80384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False  True False  True]\n",
      "[False  True False  True False]\n",
      "[ True False  True False  True]\n",
      "[ True False  True False  True]\n"
     ]
    }
   ],
   "source": [
    "test = np.array([0, 1, 2, 5, 0])\n",
    "states = [0, 2]\n",
    "mask = np.in1d(test, states)\n",
    "print(mask)\n",
    "mask1 = np.in1d(test, states,invert=True)\n",
    "print(mask1)\n",
    "mask2= np.in1d(test, states,assume_unique=True)\n",
    "print(mask2)\n",
    "mask3 = np.in1d(test, states,assume_unique=False)\n",
    "print(mask3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd4f09e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0, 11],\n",
      "        [ 1, 12],\n",
      "        [ 0, 13],\n",
      "        [ 0, 14]])\n",
      "tensor([0, 1, 0, 0])\n",
      "tensor([11, 12, 13, 14])\n",
      "tensor([[ 0, 21],\n",
      "        [ 1, 22],\n",
      "        [ 0, 23],\n",
      "        [ 0, 24]])\n",
      "(tensor([0, 1, 0, 0]), tensor([0, 1, 0, 0]))\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "p=[(0,11),(1,12),(0,13),(0,14)]\n",
    "p=torch.LongTensor(p)\n",
    "print(p)\n",
    "\n",
    "q=p[:,0]\n",
    "print(q)\n",
    "\n",
    "r=p[:,1]\n",
    "print(r)\n",
    "\n",
    "d=[(0,21),(1,22),(0,23),(0,24)]\n",
    "d=torch.LongTensor(d)\n",
    "print(d)\n",
    "\n",
    "e=(p[:,0],d[:,0])\n",
    "print(e)\n",
    "print(type(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adfdcf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'set'>, {})\n",
      "defaultdict(<class 'set'>, {(1, 2): {3}})\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "a=defaultdict(set)\n",
    "b=defaultdict(set)\n",
    "print(a)\n",
    "a[(1,2)].add(3)\n",
    "print(a)\n",
    "print(a['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79a08435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([20, 91, 88])\n"
     ]
    }
   ],
   "source": [
    "r=torch.randint(100,size=(3,))\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee7ef5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Dataset):\n",
    "    def __init__(self, triples, num_entities, num_negative_samples, all_triples=None, data_type=\"train\"):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.triples = triples\n",
    "        self.num_entities = num_entities\n",
    "        self.num_negative_samples = num_negative_samples\n",
    "        self.all_triples = all_triples\n",
    "        self.data_type = data_type\n",
    "        self.len = len(triples)\n",
    "        self.true_head_relation, self.true_relation_tail = self._get_true_head_tail_lists()\n",
    "\n",
    "     \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        positive_sample=self.triples[idx]\n",
    "        head, relation, tail = positive_sample\n",
    "        positive_sample=torch.LongTensor(positive_sample)\n",
    "        \n",
    "        if self.data_type == 'train':\n",
    "            true_heads=self.true_relation_tail[(relation, tail)]\n",
    "            true_tails=self.true_head_relation[(head, relation)]\n",
    "            \n",
    "            corrupted_heads=[]\n",
    "            corrupted=np.random.randint(self.num_entities, size=self.num_negative_samples*2)\n",
    "            while len(corrupted_heads) < self.num_negative_samples:\n",
    "                mask=np.in1d(corrupted, true_heads, assume_unique=True, invert=True)\n",
    "                corrupted=corrupted[mask]\n",
    "                corrupted_heads.extend(corrupted)\n",
    "            corrupted_heads=corrupted_heads[:self.num_negative_samples]\n",
    "            corrupted_heads=torch.LongTensor(corrupted_heads)\n",
    "            \n",
    "            corrupted_tails=[]\n",
    "            corrupted=np.random.randint(self.num_entities, size=self.num_negative_samples*2)\n",
    "            while len(corrupted_tails) < self.num_negative_samples:\n",
    "                mask=np.in1d(corrupted, true_tails, assume_unique=True, invert=True)\n",
    "                corrupted=corrupted[mask]\n",
    "                corrupted_tails.extend(corrupted)\n",
    "            corrupted_tails=corrupted_tails[:self.num_negative_samples]\n",
    "            corrupted_tails=torch.LongTensor(corrupted_tails)\n",
    "            \n",
    "            filter_bias=torch.LongTensor([0]*len(positive_sample))\n",
    "        \n",
    "        else:\n",
    "            corrupted_heads=[(0, test_head) if (test_head, relation, tail) not in self.all_triples\n",
    "                            else (-1, head) for test_head in range(self.num_entities)]\n",
    "            corrupted_heads[head]=(0,head)\n",
    "            corrupted_heads=torch.LongTensor(corrupted_heads)\n",
    "            \n",
    "            corrupted_tails=[(0, test_tail) if (head, relation, test_tail) not in self.all_triples\n",
    "                            else (-1, tail) for test_tail in range(self.num_entities)]\n",
    "            corrupted_tails[tail]=(0,tail)\n",
    "            corrupted_tails=torch.LongTensor(corrupted_tails)\n",
    "            \n",
    "            filter_bias=(corrupted_heads[:,0], corrupted_tails[:,0])\n",
    "            corrupted_heads=corrupted_heads[:,1]\n",
    "            corrupted_tails=corrupted_tails[:,1]\n",
    "        \n",
    "        return positive_sample, corrupted_heads, corrupted_tails, filter_bias    \n",
    "    \n",
    "    def _get_true_head_tail_lists(self):\n",
    "        true_head_relation=defaultdict(set)\n",
    "        true_relation_tail=defaultdict(set)\n",
    "        for triplet in self.triples:\n",
    "            head, relation, tail = triplet\n",
    "            true_head_relation[(head, relation)].add(tail)\n",
    "            true_relation_tail[(relation, tail)].add(head)\n",
    "        return true_head_relation, true_relation_tail    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddc30ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(triples, num_entities, num_negative_samples, batch_size,\n",
    "                    all_triples=None, data_type='train', num_workers=2):\n",
    "    \n",
    "    return DataLoader(\n",
    "        DataGenerator(triples, num_entities, num_negative_samples, all_triples=all_triples, data_type=data_type),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d6c90a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [-1.,  1.,  4.]])\n",
      "tensor([2., 3., 7.])\n",
      "tensor([6., 6.])\n",
      "tensor([1.4142, 2.2361, 5.0000])\n",
      "tensor([3.7417, 4.2426])\n"
     ]
    }
   ],
   "source": [
    "from torch import linalg as LA \n",
    "    \n",
    "c = torch.tensor([[1., 2., 3.],\n",
    "                 [-1, 1, 4]])\n",
    "print(c)\n",
    "print(LA.norm(c, ord=1, dim=0))\n",
    "print(LA.norm(c, ord=1, dim=1))\n",
    "# print(LA.norm(c, ord=1, dim=2))\n",
    "print(LA.norm(c, ord=2, dim=0))\n",
    "print(LA.norm(c, ord=2, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59ef657c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 4, 4, 4],\n",
      "        [4, 3, 4, 3],\n",
      "        [4, 4, 4, 3],\n",
      "        [3, 3, 3, 3]])\n",
      "e1 size  torch.Size([4, 4])\n",
      "tensor([1, 0])\n",
      "torch.Size([2, 1, 4])\n",
      "tensor([[[4, 3, 4, 3]],\n",
      "\n",
      "        [[4, 4, 4, 4]]])\n",
      "torch.Size([2, 4])\n",
      "tensor([[4, 3, 4, 3],\n",
      "        [4, 4, 4, 4]])\n",
      "torch.Size([1, 2, 4])\n",
      "tensor([[[4, 3, 4, 3],\n",
      "         [4, 4, 4, 4]]])\n",
      "torch.Size([2, 4, 1])\n",
      "tensor([[[4],\n",
      "         [3],\n",
      "         [4],\n",
      "         [3]],\n",
      "\n",
      "        [[4],\n",
      "         [4],\n",
      "         [4],\n",
      "         [4]]])\n",
      "torch.Size([1, 2, 4])\n",
      "tensor([[[4, 3, 4, 3],\n",
      "         [4, 4, 4, 4]]])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "e1 = torch.randint(3,5,(4, 4))\n",
    "print(e1)\n",
    "print('e1 size ',e1.size())\n",
    "z= torch.tensor([1, 0])\n",
    "\n",
    "print(z)\n",
    "h1 = torch.index_select(\n",
    "          e1,\n",
    "          dim=0,\n",
    "          index=z).unsqueeze(1)\n",
    "\n",
    "\n",
    "print(h1.size())\n",
    "print(h1)\n",
    "\n",
    "h2 = torch.index_select(\n",
    "          e1,\n",
    "          dim=0,\n",
    "          index=z)\n",
    "\n",
    "print(h2.size())\n",
    "print(h2)\n",
    "\n",
    "h3 = torch.index_select(\n",
    "          e1,\n",
    "          dim=0,\n",
    "          index=z).unsqueeze(0)\n",
    "\n",
    "\n",
    "print(h3.size())\n",
    "print(h3)\n",
    "\n",
    "h4 = torch.index_select(\n",
    "          e1,\n",
    "          dim=0,\n",
    "          index=z).unsqueeze(2)\n",
    "\n",
    "\n",
    "print(h4.size())\n",
    "print(h4)\n",
    "\n",
    "h5 = torch.index_select(\n",
    "          e1,\n",
    "          dim=0,\n",
    "          index=z).unsqueeze(-3)\n",
    "\n",
    "\n",
    "print(h5.size())\n",
    "print(h5)\n",
    "\n",
    "z1=torch.tensor([[1, 0],[2,3]])\n",
    "print(z1.size())\n",
    "print(z1.view(-1).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d37884ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transE(head, relation, tail, sample_type, margin):\n",
    "    dist=head + relation - tail\n",
    "    score=margin- torch.linalg.norm(dist, ord=1, dim=2)\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "533a1383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75eab002",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KGEmbedding(nn.Module):\n",
    "    def __init__(self, num_entities, num_relations, hidden_dim, margin, model):\n",
    "        super(KGEmbedding, self).__init__()\n",
    "        self.num_entities=num_entities\n",
    "        self.num_relations=num_relations\n",
    "    \n",
    "        self.entity_dim=2*hidden_dim if model == 'rotatE' else hidden_dim \n",
    "        self.relation_dim=hidden_dim\n",
    "        self.margin=margin\n",
    "        self.model=model\n",
    "        self.epsilon=2.0\n",
    "        \n",
    "        self.embedding_range= (self.margin + self.epsilon)/hidden_dim\n",
    "        \n",
    "        self.entity_embed = nn.Parameter(torch.zeros(self.num_entities, self.entity_dim,\n",
    "                                                    requires_grad=True))\n",
    "        \n",
    "        nn.init.uniform_(\n",
    "            self.entity_embed,\n",
    "            a=-self.embedding_range,\n",
    "            b=self.embedding_range\n",
    "        )\n",
    "        \n",
    "        self.relation_embed=nn.Parameter(torch.zeros(self.num_relations, self.relation_dim,\n",
    "                                                    requires_grad=True))\n",
    "        \n",
    "        nn.init.uniform_(\n",
    "            self.relation_embed,\n",
    "            a=-self.embedding_range,\n",
    "            b=self.embedding_range\n",
    "        )\n",
    "    \n",
    "    def forward(self, sample, sample_type):\n",
    "        \n",
    "        if sample_type=='positive':\n",
    "            head=torch.index_select(\n",
    "                self.entity_embed,\n",
    "                dim=0,\n",
    "                index=sample[:,0]\n",
    "            ).unsqueeze(1)\n",
    "            \n",
    "            relation=torch.index_select(\n",
    "                self.relation_embed,\n",
    "                dim=0,\n",
    "                index=sample[:,1]\n",
    "            ).unsqueeze(1)\n",
    "            \n",
    "            tail=torch.index_select(\n",
    "                self.entity_embed,\n",
    "                dim=0,\n",
    "                index=sample[:,2]\n",
    "            ).unsqueeze(1)\n",
    "            \n",
    "        elif sample_type=='negative-head':\n",
    "            \n",
    "            positive_tuple, negative_head_entities = sample\n",
    "            batch_size, num_neg_samples = negative_head_entities.shape\n",
    "            \n",
    "            head=torch.index_select(\n",
    "                self.entity_embed,\n",
    "                dim=0,\n",
    "                index=negative_head_entities.view(-1)\n",
    "            ).reshape(batch_size, num_neg_samples, self.entity_dim)\n",
    "            \n",
    "            relation = torch.index_select(\n",
    "                    self.relation_embed,\n",
    "                    dim=0,\n",
    "                    index=positive_tuple[:,1]\n",
    "            ).unsqueeze(1)\n",
    "            \n",
    "            tail=torch.index_select(\n",
    "                self.entity_embed,\n",
    "                dim=0,\n",
    "                index=positive_tuple[:,2]\n",
    "            ).unsqueeze(1)\n",
    "            \n",
    "        elif sample_type == 'negative-tail':\n",
    "            positive_tuple, negative_tail_entities = sample\n",
    "            batch_size, num_neg_samples = negative_tail_entities.shape\n",
    "            \n",
    "            head=torch.index_select(\n",
    "                self.entity_embed,\n",
    "                dim=0,\n",
    "                index=positive_tuple[:,0]\n",
    "            ).unsqueeze(1)\n",
    "            \n",
    "            relation=torch.index_select(\n",
    "                self.relation_embed,\n",
    "                dim=0,\n",
    "                index=positive_tuple[:,1]\n",
    "            ).unsqueeze(1)\n",
    "            \n",
    "            tail=torch.index_select(\n",
    "                self.entity_embed,\n",
    "                dim=0,\n",
    "                index=negative_tail_entities.view(-1)\n",
    "            ).reshape(batch_size, num_neg_samples, self.entity_dim)\n",
    "            \n",
    "         \n",
    "        if self.model == 'rotatE':\n",
    "            return rotatE(head, relation, tail, self.embedding_range, sample_type, self.margin)\n",
    "        elif self.model == 'transE':\n",
    "            return transE(head, relation, tail, sample_type, self.margin)\n",
    "            \n",
    "            \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c45699c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import trange\n",
    "\n",
    "DATA_DIR = './FB15k-237/'\n",
    "MODEL_DIR='models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37dfc27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helloabc\n",
      "  abc\tdef pq  \n",
      "abc\tdef pq\n",
      "['abc', 'def pq']\n",
      "checkpoint_{3}\n"
     ]
    }
   ],
   "source": [
    "s='  hello  '\n",
    "print(s.strip()+'abc')\n",
    "\n",
    "w='  abc\\tdef pq  '\n",
    "print(w)\n",
    "w1=w.strip()\n",
    "print(w1)\n",
    "w2=w1.split('\\t')\n",
    "print(w2)\n",
    "\n",
    "print('checkpoint_{3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "293be939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(file_path):\n",
    "    loaded_dict=dict()\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            uid, val = line.strip().split('\\t')\n",
    "            loaded_dict[val]=int(uid)\n",
    "    \n",
    "    return loaded_dict         \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4e43497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_triples(file_path, entity2id, relation2id):\n",
    "    triples=list()\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            head, relation, tail = line.strip().split('\\t')\n",
    "            triples.append((entity2id[head], relation2id[relation], entity2id[tail]))\n",
    "    return triples        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe34d285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, scheduler, epoch):\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        os.makedirs(MODEL_DIR)\n",
    "        \n",
    "    torch.save({\n",
    "        'model_state_dict':model.state_dict(),\n",
    "        'optimizer_state_dict':optimizer.state_dict(),\n",
    "        'scheduler_state_dict':scheduler.state_dict()\n",
    "    },\n",
    "        os.path.join(MODEL_DIR,f'checkpoint_{epoch}')\n",
    "    )\n",
    "    \n",
    "    entity_embedding=model.entity_embed.detach().cpu().numpy()\n",
    "    np.save(os.path.join(MODEL_DIR, f'entity_embedding_{epoch}'),entity_embedding)\n",
    "    \n",
    "    relation_embedding=model.relation_embed.detach().cpu().numpy()\n",
    "    np.save(os.path.join(MODEL_DIR, f'relation_embedding_{epoch}'), relation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d85a618c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "tensor([[3, 3, 3, 3],\n",
      "        [2, 2, 2, 2],\n",
      "        [1, 1, 1, 1],\n",
      "        [0, 0, 0, 0]])\n",
      "test_{q2}\n",
      "test_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 4/4 [00:00<00:00, 16794.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(16).view(-1,4)\n",
    "print(a)\n",
    "\n",
    "z= torch.argsort(a,dim=0,descending=True)\n",
    "print(z)\n",
    "\n",
    "q2=5\n",
    "print('test_{q2}')\n",
    "print(f'test_{q2}')\n",
    "\n",
    "for i in trange(z.shape[0]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aac761b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8781180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data, num_entities, _num_negative_samples, _batch_size, all_data, data_type):\n",
    "    model.eval()\n",
    "    \n",
    "    dataloader=get_data_loader(data, num_entities, _num_negative_samples, _batch_size, all_triples=all_data, data_type=data_type)\n",
    "    \n",
    "    final_metrics=defaultdict(float)\n",
    "    dataset_metrics=[]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch, (positive_sample, corrupted_heads, corrupted_tails, filter_bias) in enumerate(dataloader):\n",
    "            head_bias, tail_bias = filter_bias\n",
    "            if torch.cuda.is_available():\n",
    "                positive_sample=positive_sample.cuda()\n",
    "                corrupted_heads=corrupted_heads.cuda()\n",
    "                corrupted_tails=corrupted_tails.cuda()\n",
    "                head_bias=head_bias.cuda()\n",
    "                tail_bias=tail_bias.cuda()\n",
    "                \n",
    "                \n",
    "            corrupted_head_dist=model((positive_sample, corrupted_heads), 'negative-head') + head_bias\n",
    "            corrupted_tail_dist=model((positive_sample, corrupted_tails), 'negative-tail') + tail_bias\n",
    "            \n",
    "            head_arg_order=torch.argsort(corrupted_head_dist, dim=1, descending=True)\n",
    "            tail_arg_order=torch.argsort(corrupted_tail_dist, dim=1, descending=True)\n",
    "            \n",
    "            true_head=positive_sample[:,0]\n",
    "            true_tail=positive_sample[:,2]\n",
    "            \n",
    "            for ind in range(len(true_head)):\n",
    "                true_head_rank=(head_arg_order[ind,:] == true_head[ind]).nonzero()\n",
    "                true_head_rank = true_head_rank.item() + 1\n",
    "                \n",
    "                true_tail_rank = (tail_arg_order[ind,:] == true_tail[ind]).nonzero()\n",
    "                true_tail_rank = true_tail_rank.item() + 1\n",
    "                \n",
    "                dataset_metrics.append({\n",
    "                    'MRR': 1.0/true_head_rank,\n",
    "                    'MR':float(true_head_rank),\n",
    "                    'HITS@1':1.0 if true_head_rank <=1 else 0.0,\n",
    "                    'HITS@3':1.0 if true_head_rank <=3 else 0.0,\n",
    "                    'HITS@10':1.0 if true_head_rank <=10 else 0.0\n",
    "                    \n",
    "                })\n",
    "                \n",
    "                dataset_metrics.append({\n",
    "                    'MRR': 1.0/true_tail_rank,\n",
    "                    'MR':float(true_tail_rank),\n",
    "                    'HITS@1':1.0 if true_tail_rank <=1 else 0.0,\n",
    "                    'HITS@3':1.0 if true_tail_rank <=3 else 0.0,\n",
    "                    'HITS@10':1.0 if true_tail_rank <=10 else 0.0\n",
    "                    \n",
    "                })\n",
    "                \n",
    "        for metric in dataset_metrics:\n",
    "            for key, val in metric.items():\n",
    "                final_metrics[key] += val\n",
    "        \n",
    "        for key,val in final_metrics.items():\n",
    "            final_metrics[key] = val/len(dataset_metrics)\n",
    "        \n",
    "        print(f'{data_type} metrics: {final_metrics}')\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45fa8074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    _num_negative_samples=128\n",
    "    _batch_size=1024\n",
    "    _test_batch_size=16\n",
    "    _lr=0.0001\n",
    "    _hidden_dim=1000\n",
    "    _margin=12\n",
    "    _num_epochs=1\n",
    "    _weight_decay=5e-5\n",
    "    _cuda=torch.cuda.is_available()\n",
    "    \n",
    "    entity2id = load_dict(os.path.join(DATA_DIR, 'entities.dict'))\n",
    "    relation2id = load_dict(os.path.join(DATA_DIR, 'relations.dict'))\n",
    "    num_entities=len(entity2id)\n",
    "    num_relations=len(relation2id)\n",
    "    \n",
    "    train_data=load_triples(os.path.join(DATA_DIR, 'train.txt'), entity2id, relation2id)\n",
    "    eval_data=load_triples(os.path.join(DATA_DIR, 'valid.txt'), entity2id, relation2id)\n",
    "    test_data=load_triples(os.path.join(DATA_DIR, 'test.txt'), entity2id, relation2id)\n",
    "    print(f'train length {len(train_data)}')\n",
    "    print(f'eval length {len(eval_data)}')\n",
    "    print(f'test length {len(test_data)}')\n",
    "    all_data=[train_data, eval_data, test_data]\n",
    "    \n",
    "    dataloader = get_data_loader(train_data, num_entities, _num_negative_samples, _batch_size, data_type='train')\n",
    "    \n",
    "    model=KGEmbedding(num_entities, num_relations, _hidden_dim, _margin, 'transE')\n",
    "    if _cuda:\n",
    "        model=model.cuda()\n",
    "        \n",
    "    optimizer=torch.optim.Adam(filter(lambda p:p.requires_grad, model.parameters()), lr=_lr, weight_decay= _weight_decay)\n",
    "    scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n",
    "    \n",
    "    print('Start Training...')\n",
    "    for epoch in trange(_num_epochs, desc='Train', unit='Epoch'):\n",
    "        total_loss=0\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        print('enumerate length ',enumerate(dataloader))\n",
    "        for batch, (positive_sample, corrupted_heads, corrupted_tails, _) in enumerate(dataloader):\n",
    "            if _cuda:\n",
    "                positive_sample=positive_sample.cuda()\n",
    "                corrupted_heads=corrupted_heads.cuda()\n",
    "                corrupted_tails=corrupted_tails.cuda()\n",
    "                \n",
    "            positive_sample_dist=model(positive_sample, 'positive')\n",
    "            positive_score=F.logsigmoid(positive_sample_dist)\n",
    "            positive_sample_loss=-positive_score.mean()\n",
    "            \n",
    "            corrupted_head_dist=model((positive_sample, corrupted_heads), 'negative-head')\n",
    "            corrupted_head_score=F.logsigmoid(-corrupted_head_dist)\n",
    "            corrupted_head_loss=-corrupted_head_score.mean()\n",
    "            \n",
    "            corrupted_tail_dist=model((positive_sample, corrupted_tails),'negative-tail')\n",
    "            corrupted_tail_score=F.logsigmoid(-corrupted_tail_dist)\n",
    "            corrupted_tail_loss=-corrupted_tail_score.mean()\n",
    "            \n",
    "            loss=(positive_sample_loss + corrupted_head_loss + positive_sample_loss + corrupted_tail_loss)/4\n",
    "            total_loss+=loss.item()\n",
    "            \n",
    "            print(f'\\nbatch: {batch}, loss: {loss}, pos_loss: {positive_sample_loss}, neg_head_loss:{corrupted_head_loss}, neg_tail_loss: {corrupted_tail_loss}')\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "        scheduler.step(total_loss)\n",
    "        print(f'\\nepoch: {epoch}, avg loss:{total_loss/len(dataloader)}')\n",
    "        \n",
    "       \n",
    "        if epoch==0:\n",
    "            eval_model(model,eval_data, num_entities, _num_negative_samples, _test_batch_size, all_data, 'eval')\n",
    "            save_model(model, optimizer, scheduler, epoch)\n",
    "        \n",
    "        \n",
    "    eval_model(model, test_data, num_entities, _num_negative_samples, _test_batch_size, all_data, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c0b6712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train length 272115\n",
      "eval length 17535\n",
      "test length 20466\n",
      "Start Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train:   0%|                                           | 0/1 [00:00<?, ?Epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enumerate length  <enumerate object at 0x7fb3654625a0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch: 0, loss: 0.7465620040893555, pos_loss: 0.4462284445762634, neg_head_loss:1.043308973312378, neg_tail_loss: 1.0504820346832275\n",
      "\n",
      "batch: 1, loss: 0.7308329343795776, pos_loss: 0.46657195687294006, neg_head_loss:0.9965364336967468, neg_tail_loss: 0.9936514496803284\n",
      "\n",
      "batch: 2, loss: 0.7192634344100952, pos_loss: 0.49911510944366455, neg_head_loss:0.944808840751648, neg_tail_loss: 0.9340145587921143\n",
      "\n",
      "batch: 3, loss: 0.7088199853897095, pos_loss: 0.5212148427963257, neg_head_loss:0.9046688675880432, neg_tail_loss: 0.8881813883781433\n",
      "\n",
      "batch: 4, loss: 0.7010917663574219, pos_loss: 0.5516703724861145, neg_head_loss:0.8580695390701294, neg_tail_loss: 0.8429567813873291\n",
      "\n",
      "batch: 5, loss: 0.6913243532180786, pos_loss: 0.5683934092521667, neg_head_loss:0.825359046459198, neg_tail_loss: 0.803151547908783\n",
      "\n",
      "batch: 6, loss: 0.6860454678535461, pos_loss: 0.5988953113555908, neg_head_loss:0.7852234244346619, neg_tail_loss: 0.7611677646636963\n",
      "\n",
      "batch: 7, loss: 0.6793630123138428, pos_loss: 0.6210020184516907, neg_head_loss:0.7579400539398193, neg_tail_loss: 0.71750807762146\n",
      "\n",
      "batch: 8, loss: 0.676662266254425, pos_loss: 0.6563059091567993, neg_head_loss:0.7152582406997681, neg_tail_loss: 0.678778886795044\n",
      "\n",
      "batch: 9, loss: 0.6723207235336304, pos_loss: 0.6711093783378601, neg_head_loss:0.6963111162185669, neg_tail_loss: 0.6507530212402344\n",
      "\n",
      "batch: 10, loss: 0.6718430519104004, pos_loss: 0.706950306892395, neg_head_loss:0.6594445705413818, neg_tail_loss: 0.6140270233154297\n",
      "\n",
      "batch: 11, loss: 0.6689183712005615, pos_loss: 0.730491042137146, neg_head_loss:0.6322431564331055, neg_tail_loss: 0.5824483036994934\n",
      "\n",
      "batch: 12, loss: 0.6626976728439331, pos_loss: 0.7371748685836792, neg_head_loss:0.6185040473937988, neg_tail_loss: 0.5579367876052856\n",
      "\n",
      "batch: 13, loss: 0.6642854809761047, pos_loss: 0.7654075622558594, neg_head_loss:0.587919294834137, neg_tail_loss: 0.538407564163208\n",
      "\n",
      "batch: 14, loss: 0.6655124425888062, pos_loss: 0.791357159614563, neg_head_loss:0.576720118522644, neg_tail_loss: 0.5026155114173889\n",
      "\n",
      "batch: 15, loss: 0.6651160717010498, pos_loss: 0.8107750415802002, neg_head_loss:0.5547338724136353, neg_tail_loss: 0.48418042063713074\n",
      "\n",
      "batch: 16, loss: 0.6569011211395264, pos_loss: 0.8065365552902222, neg_head_loss:0.5428512692451477, neg_tail_loss: 0.4716801345348358\n",
      "\n",
      "batch: 17, loss: 0.6617885828018188, pos_loss: 0.8353508114814758, neg_head_loss:0.5272296667098999, neg_tail_loss: 0.4492230713367462\n",
      "\n",
      "batch: 18, loss: 0.6628196835517883, pos_loss: 0.850022554397583, neg_head_loss:0.512485146522522, neg_tail_loss: 0.43874865770339966\n",
      "\n",
      "batch: 19, loss: 0.6702159643173218, pos_loss: 0.8786338567733765, neg_head_loss:0.5038559436798096, neg_tail_loss: 0.419740229845047\n",
      "\n",
      "batch: 20, loss: 0.6661441326141357, pos_loss: 0.8784338235855103, neg_head_loss:0.48740869760513306, neg_tail_loss: 0.4202999770641327\n",
      "\n",
      "batch: 21, loss: 0.6591887474060059, pos_loss: 0.8706374764442444, neg_head_loss:0.48578599095344543, neg_tail_loss: 0.4096938669681549\n",
      "\n",
      "batch: 22, loss: 0.6556784510612488, pos_loss: 0.8592234253883362, neg_head_loss:0.49537354707717896, neg_tail_loss: 0.40889325737953186\n",
      "\n",
      "batch: 23, loss: 0.6562856435775757, pos_loss: 0.8671814799308777, neg_head_loss:0.49587398767471313, neg_tail_loss: 0.3949055075645447\n",
      "\n",
      "batch: 24, loss: 0.6483200788497925, pos_loss: 0.8533221483230591, neg_head_loss:0.4962936043739319, neg_tail_loss: 0.39034223556518555\n",
      "\n",
      "batch: 25, loss: 0.643445611000061, pos_loss: 0.8380295634269714, neg_head_loss:0.5035068392753601, neg_tail_loss: 0.3942165970802307\n",
      "\n",
      "batch: 26, loss: 0.6520711183547974, pos_loss: 0.8553263545036316, neg_head_loss:0.5016111135482788, neg_tail_loss: 0.39602068066596985\n",
      "\n",
      "batch: 27, loss: 0.6419834494590759, pos_loss: 0.8232146501541138, neg_head_loss:0.5184803009033203, neg_tail_loss: 0.4030241072177887\n",
      "\n",
      "batch: 28, loss: 0.6400686502456665, pos_loss: 0.8129304647445679, neg_head_loss:0.5242480039596558, neg_tail_loss: 0.4101659059524536\n",
      "\n",
      "batch: 29, loss: 0.6264129877090454, pos_loss: 0.7767381072044373, neg_head_loss:0.536711573600769, neg_tail_loss: 0.41546428203582764\n",
      "\n",
      "batch: 30, loss: 0.6334390640258789, pos_loss: 0.788474440574646, neg_head_loss:0.5249650478363037, neg_tail_loss: 0.4318423569202423\n",
      "\n",
      "batch: 31, loss: 0.632159411907196, pos_loss: 0.7735803723335266, neg_head_loss:0.5536656975746155, neg_tail_loss: 0.4278111755847931\n",
      "\n",
      "batch: 32, loss: 0.630294680595398, pos_loss: 0.7557316422462463, neg_head_loss:0.5710290670394897, neg_tail_loss: 0.4386864900588989\n",
      "\n",
      "batch: 33, loss: 0.6213424205780029, pos_loss: 0.7295505404472351, neg_head_loss:0.5844727754592896, neg_tail_loss: 0.44179582595825195\n",
      "\n",
      "batch: 34, loss: 0.6235539317131042, pos_loss: 0.7183315753936768, neg_head_loss:0.5906491875648499, neg_tail_loss: 0.466903418302536\n",
      "\n",
      "batch: 35, loss: 0.6252238750457764, pos_loss: 0.6980573534965515, neg_head_loss:0.60686194896698, neg_tail_loss: 0.4979187548160553\n",
      "\n",
      "batch: 36, loss: 0.6054885387420654, pos_loss: 0.6413866877555847, neg_head_loss:0.6422553658485413, neg_tail_loss: 0.496925413608551\n",
      "\n",
      "batch: 37, loss: 0.6176473498344421, pos_loss: 0.6544646620750427, neg_head_loss:0.6535800695419312, neg_tail_loss: 0.5080800652503967\n",
      "\n",
      "batch: 38, loss: 0.6208351850509644, pos_loss: 0.6536569595336914, neg_head_loss:0.6584835052490234, neg_tail_loss: 0.5175433158874512\n",
      "\n",
      "batch: 39, loss: 0.6179255247116089, pos_loss: 0.6242496967315674, neg_head_loss:0.6938676834106445, neg_tail_loss: 0.5293349623680115\n",
      "\n",
      "batch: 40, loss: 0.6119035482406616, pos_loss: 0.5942034721374512, neg_head_loss:0.7034059762954712, neg_tail_loss: 0.5558013916015625\n",
      "\n",
      "batch: 41, loss: 0.6053759455680847, pos_loss: 0.5496276617050171, neg_head_loss:0.7508072853088379, neg_tail_loss: 0.571441113948822\n",
      "\n",
      "batch: 42, loss: 0.6240950226783752, pos_loss: 0.5880684852600098, neg_head_loss:0.7381383180618286, neg_tail_loss: 0.5821048021316528\n",
      "\n",
      "batch: 43, loss: 0.6161260008811951, pos_loss: 0.5583437085151672, neg_head_loss:0.7592657804489136, neg_tail_loss: 0.5885508060455322\n",
      "\n",
      "batch: 44, loss: 0.6161044239997864, pos_loss: 0.5449702739715576, neg_head_loss:0.7887758016586304, neg_tail_loss: 0.5857012867927551\n",
      "\n",
      "batch: 45, loss: 0.6356521844863892, pos_loss: 0.5626108646392822, neg_head_loss:0.8033496141433716, neg_tail_loss: 0.614037275314331\n",
      "\n",
      "batch: 46, loss: 0.6205240488052368, pos_loss: 0.5054025053977966, neg_head_loss:0.8519826531410217, neg_tail_loss: 0.6193084716796875\n",
      "\n",
      "batch: 47, loss: 0.6246464252471924, pos_loss: 0.5164477825164795, neg_head_loss:0.834669828414917, neg_tail_loss: 0.6310202479362488\n",
      "\n",
      "batch: 48, loss: 0.6193247437477112, pos_loss: 0.48663485050201416, neg_head_loss:0.866304337978363, neg_tail_loss: 0.6377249956130981\n",
      "\n",
      "batch: 49, loss: 0.6389189958572388, pos_loss: 0.5265548229217529, neg_head_loss:0.8363860845565796, neg_tail_loss: 0.6661802530288696\n",
      "\n",
      "batch: 50, loss: 0.6290124654769897, pos_loss: 0.4904157817363739, neg_head_loss:0.854677140712738, neg_tail_loss: 0.6805411577224731\n",
      "\n",
      "batch: 51, loss: 0.6208609342575073, pos_loss: 0.45761117339134216, neg_head_loss:0.8763896226882935, neg_tail_loss: 0.6918315887451172\n",
      "\n",
      "batch: 52, loss: 0.6174734234809875, pos_loss: 0.4575386047363281, neg_head_loss:0.8963798880577087, neg_tail_loss: 0.6584364771842957\n",
      "\n",
      "batch: 53, loss: 0.6399038434028625, pos_loss: 0.5125662088394165, neg_head_loss:0.8759854435920715, neg_tail_loss: 0.6584974527359009\n",
      "\n",
      "batch: 54, loss: 0.6476457118988037, pos_loss: 0.5190710425376892, neg_head_loss:0.8821736574172974, neg_tail_loss: 0.6702672243118286\n",
      "\n",
      "batch: 55, loss: 0.6331892013549805, pos_loss: 0.4753710627555847, neg_head_loss:0.903313934803009, neg_tail_loss: 0.6787008047103882\n",
      "\n",
      "batch: 56, loss: 0.6436969041824341, pos_loss: 0.5155763626098633, neg_head_loss:0.8831299543380737, neg_tail_loss: 0.6605050563812256\n",
      "\n",
      "batch: 57, loss: 0.6361919641494751, pos_loss: 0.5000597238540649, neg_head_loss:0.8708212375640869, neg_tail_loss: 0.673827052116394\n",
      "\n",
      "batch: 58, loss: 0.6429940462112427, pos_loss: 0.5191197395324707, neg_head_loss:0.8506206274032593, neg_tail_loss: 0.68311607837677\n",
      "\n",
      "batch: 59, loss: 0.62819904088974, pos_loss: 0.5027420520782471, neg_head_loss:0.8469648361206055, neg_tail_loss: 0.6603472828865051\n",
      "\n",
      "batch: 60, loss: 0.6232396364212036, pos_loss: 0.5026324391365051, neg_head_loss:0.8483191728591919, neg_tail_loss: 0.6393746137619019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch: 61, loss: 0.634114146232605, pos_loss: 0.5172774195671082, neg_head_loss:0.8498169779777527, neg_tail_loss: 0.6520848870277405\n",
      "\n",
      "batch: 62, loss: 0.635489821434021, pos_loss: 0.5484999418258667, neg_head_loss:0.824034571647644, neg_tail_loss: 0.6209248304367065\n",
      "\n",
      "batch: 63, loss: 0.6394551992416382, pos_loss: 0.5647528767585754, neg_head_loss:0.8320375084877014, neg_tail_loss: 0.5962774157524109\n",
      "\n",
      "batch: 64, loss: 0.632889986038208, pos_loss: 0.5804691910743713, neg_head_loss:0.7787421941757202, neg_tail_loss: 0.5918792486190796\n",
      "\n",
      "batch: 65, loss: 0.6317517757415771, pos_loss: 0.5868316888809204, neg_head_loss:0.780223548412323, neg_tail_loss: 0.5731201171875\n",
      "\n",
      "batch: 66, loss: 0.622559130191803, pos_loss: 0.5781962275505066, neg_head_loss:0.744610071182251, neg_tail_loss: 0.5892338752746582\n",
      "\n",
      "batch: 67, loss: 0.6276529431343079, pos_loss: 0.6049954891204834, neg_head_loss:0.7446123361587524, neg_tail_loss: 0.5560083985328674\n",
      "\n",
      "batch: 68, loss: 0.6129528880119324, pos_loss: 0.5888490080833435, neg_head_loss:0.7221893072128296, neg_tail_loss: 0.5519241690635681\n",
      "\n",
      "batch: 69, loss: 0.619533360004425, pos_loss: 0.636074423789978, neg_head_loss:0.6918008327484131, neg_tail_loss: 0.5141837000846863\n",
      "\n",
      "batch: 70, loss: 0.6134428977966309, pos_loss: 0.646049976348877, neg_head_loss:0.6700800657272339, neg_tail_loss: 0.49159157276153564\n",
      "\n",
      "batch: 71, loss: 0.6346832513809204, pos_loss: 0.6941271424293518, neg_head_loss:0.6688914895057678, neg_tail_loss: 0.48158717155456543\n",
      "\n",
      "batch: 72, loss: 0.5915675163269043, pos_loss: 0.6386573314666748, neg_head_loss:0.6159281134605408, neg_tail_loss: 0.4730271100997925\n",
      "\n",
      "batch: 73, loss: 0.6042079925537109, pos_loss: 0.6703681945800781, neg_head_loss:0.6204415559768677, neg_tail_loss: 0.4556540846824646\n",
      "\n",
      "batch: 74, loss: 0.63089919090271, pos_loss: 0.747650146484375, neg_head_loss:0.5939241647720337, neg_tail_loss: 0.43437254428863525\n",
      "\n",
      "batch: 75, loss: 0.6387505531311035, pos_loss: 0.787578821182251, neg_head_loss:0.552748441696167, neg_tail_loss: 0.42709603905677795\n",
      "\n",
      "batch: 76, loss: 0.6384173631668091, pos_loss: 0.8083648681640625, neg_head_loss:0.5508871078491211, neg_tail_loss: 0.38605260848999023\n",
      "\n",
      "batch: 77, loss: 0.6302881240844727, pos_loss: 0.807668149471283, neg_head_loss:0.529689371585846, neg_tail_loss: 0.3761267066001892\n",
      "\n",
      "batch: 78, loss: 0.6653652191162109, pos_loss: 0.8894952535629272, neg_head_loss:0.5114619731903076, neg_tail_loss: 0.37100836634635925\n",
      "\n",
      "batch: 79, loss: 0.6479200124740601, pos_loss: 0.873337984085083, neg_head_loss:0.4778403043746948, neg_tail_loss: 0.36716362833976746\n",
      "\n",
      "batch: 80, loss: 0.6530765295028687, pos_loss: 0.9130151271820068, neg_head_loss:0.4584021270275116, neg_tail_loss: 0.3278736472129822\n",
      "\n",
      "batch: 81, loss: 0.6600297689437866, pos_loss: 0.9456183314323425, neg_head_loss:0.42997804284095764, neg_tail_loss: 0.3189045190811157\n",
      "\n",
      "batch: 82, loss: 0.656827449798584, pos_loss: 0.9516041278839111, neg_head_loss:0.4129888415336609, neg_tail_loss: 0.31111276149749756\n",
      "\n",
      "batch: 83, loss: 0.6544886827468872, pos_loss: 0.9554781913757324, neg_head_loss:0.4059438109397888, neg_tail_loss: 0.3010544180870056\n",
      "\n",
      "batch: 84, loss: 0.7042961120605469, pos_loss: 1.0658276081085205, neg_head_loss:0.4054279327392578, neg_tail_loss: 0.2801012396812439\n",
      "\n",
      "batch: 85, loss: 0.6975064277648926, pos_loss: 1.0787389278411865, neg_head_loss:0.372225821018219, neg_tail_loss: 0.26032203435897827\n",
      "\n",
      "batch: 86, loss: 0.7126935720443726, pos_loss: 1.1188676357269287, neg_head_loss:0.3659932613372803, neg_tail_loss: 0.24704572558403015\n",
      "\n",
      "batch: 87, loss: 0.727785587310791, pos_loss: 1.1640892028808594, neg_head_loss:0.34529417753219604, neg_tail_loss: 0.2376696914434433\n",
      "\n",
      "batch: 88, loss: 0.6981803178787231, pos_loss: 1.1039807796478271, neg_head_loss:0.3426089584827423, neg_tail_loss: 0.2421507090330124\n",
      "\n",
      "batch: 89, loss: 0.7339068651199341, pos_loss: 1.1851806640625, neg_head_loss:0.32573452591896057, neg_tail_loss: 0.23953162133693695\n",
      "\n",
      "batch: 90, loss: 0.7248499393463135, pos_loss: 1.1752333641052246, neg_head_loss:0.32959866523742676, neg_tail_loss: 0.21933427453041077\n",
      "\n",
      "batch: 91, loss: 0.7003463506698608, pos_loss: 1.1330891847610474, neg_head_loss:0.32484567165374756, neg_tail_loss: 0.21036159992218018\n",
      "\n",
      "batch: 92, loss: 0.7299225926399231, pos_loss: 1.199338674545288, neg_head_loss:0.31071093678474426, neg_tail_loss: 0.2103022187948227\n",
      "\n",
      "batch: 93, loss: 0.7525382041931152, pos_loss: 1.256852626800537, neg_head_loss:0.29240283370018005, neg_tail_loss: 0.20404492318630219\n",
      "\n",
      "batch: 94, loss: 0.779844343662262, pos_loss: 1.320628046989441, neg_head_loss:0.291882187128067, neg_tail_loss: 0.18623903393745422\n",
      "\n",
      "batch: 95, loss: 0.7511458992958069, pos_loss: 1.257704734802246, neg_head_loss:0.29562652111053467, neg_tail_loss: 0.19354738295078278\n",
      "\n",
      "batch: 96, loss: 0.7311429381370544, pos_loss: 1.2304332256317139, neg_head_loss:0.2895822823047638, neg_tail_loss: 0.17412309348583221\n",
      "\n",
      "batch: 97, loss: 0.7731026411056519, pos_loss: 1.3129308223724365, neg_head_loss:0.2893083691596985, neg_tail_loss: 0.17724066972732544\n",
      "\n",
      "batch: 98, loss: 0.7590821981430054, pos_loss: 1.2882275581359863, neg_head_loss:0.27540698647499084, neg_tail_loss: 0.18446695804595947\n",
      "\n",
      "batch: 99, loss: 0.7479897141456604, pos_loss: 1.2684824466705322, neg_head_loss:0.2793791890144348, neg_tail_loss: 0.17561477422714233\n",
      "\n",
      "batch: 100, loss: 0.7320787906646729, pos_loss: 1.23795747756958, neg_head_loss:0.27668145298957825, neg_tail_loss: 0.175718754529953\n",
      "\n",
      "batch: 101, loss: 0.7465003132820129, pos_loss: 1.2628177404403687, neg_head_loss:0.29546836018562317, neg_tail_loss: 0.16489745676517487\n",
      "\n",
      "batch: 102, loss: 0.7885885238647461, pos_loss: 1.3508695363998413, neg_head_loss:0.2808988094329834, neg_tail_loss: 0.1717161238193512\n",
      "\n",
      "batch: 103, loss: 0.7660931944847107, pos_loss: 1.3036953210830688, neg_head_loss:0.2965296804904938, neg_tail_loss: 0.16045261919498444\n",
      "\n",
      "batch: 104, loss: 0.7555991411209106, pos_loss: 1.2773537635803223, neg_head_loss:0.2964842915534973, neg_tail_loss: 0.17120477557182312\n",
      "\n",
      "batch: 105, loss: 0.7539657354354858, pos_loss: 1.2722729444503784, neg_head_loss:0.30719220638275146, neg_tail_loss: 0.1641249656677246\n",
      "\n",
      "batch: 106, loss: 0.7690213322639465, pos_loss: 1.2946072816848755, neg_head_loss:0.3192015290260315, neg_tail_loss: 0.16766902804374695\n",
      "\n",
      "batch: 107, loss: 0.7463697195053101, pos_loss: 1.25486159324646, neg_head_loss:0.30694663524627686, neg_tail_loss: 0.16880889236927032\n",
      "\n",
      "batch: 108, loss: 0.7582572102546692, pos_loss: 1.271863341331482, neg_head_loss:0.3265017867088318, neg_tail_loss: 0.16280058026313782\n",
      "\n",
      "batch: 109, loss: 0.7129558324813843, pos_loss: 1.174882411956787, neg_head_loss:0.3292689025402069, neg_tail_loss: 0.17278969287872314\n",
      "\n",
      "batch: 110, loss: 0.7455076575279236, pos_loss: 1.2403326034545898, neg_head_loss:0.32905933260917664, neg_tail_loss: 0.17230595648288727\n",
      "\n",
      "batch: 111, loss: 0.7598644495010376, pos_loss: 1.2579021453857422, neg_head_loss:0.33830225467681885, neg_tail_loss: 0.18535146117210388\n",
      "\n",
      "batch: 112, loss: 0.7363825440406799, pos_loss: 1.2093006372451782, neg_head_loss:0.3448929786682129, neg_tail_loss: 0.18203584849834442\n",
      "\n",
      "batch: 113, loss: 0.7575367093086243, pos_loss: 1.2444897890090942, neg_head_loss:0.3587656021118164, neg_tail_loss: 0.1824016273021698\n",
      "\n",
      "batch: 114, loss: 0.7625899314880371, pos_loss: 1.2472407817840576, neg_head_loss:0.3590048551559448, neg_tail_loss: 0.1968732476234436\n",
      "\n",
      "batch: 115, loss: 0.7247167825698853, pos_loss: 1.1770198345184326, neg_head_loss:0.34620511531829834, neg_tail_loss: 0.19862215220928192\n",
      "\n",
      "batch: 116, loss: 0.7415949106216431, pos_loss: 1.1988525390625, neg_head_loss:0.37373921275138855, neg_tail_loss: 0.19493527710437775\n",
      "\n",
      "batch: 117, loss: 0.7361088395118713, pos_loss: 1.181368112564087, neg_head_loss:0.38262778520584106, neg_tail_loss: 0.19907133281230927\n",
      "\n",
      "batch: 118, loss: 0.7371628880500793, pos_loss: 1.1857277154922485, neg_head_loss:0.3697647154331207, neg_tail_loss: 0.2074315845966339\n",
      "\n",
      "batch: 119, loss: 0.6932615041732788, pos_loss: 1.0847806930541992, neg_head_loss:0.3884391188621521, neg_tail_loss: 0.21504545211791992\n",
      "\n",
      "batch: 120, loss: 0.7296032905578613, pos_loss: 1.1506720781326294, neg_head_loss:0.4092330038547516, neg_tail_loss: 0.2078360915184021\n",
      "\n",
      "batch: 121, loss: 0.715165913105011, pos_loss: 1.1218860149383545, neg_head_loss:0.4015462100505829, neg_tail_loss: 0.21534548699855804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch: 122, loss: 0.6898320913314819, pos_loss: 1.0489637851715088, neg_head_loss:0.428353488445282, neg_tail_loss: 0.233047217130661\n",
      "\n",
      "batch: 123, loss: 0.6967944502830505, pos_loss: 1.0655754804611206, neg_head_loss:0.43648505210876465, neg_tail_loss: 0.21954183280467987\n",
      "\n",
      "batch: 124, loss: 0.7523294687271118, pos_loss: 1.1772586107254028, neg_head_loss:0.4228661358356476, neg_tail_loss: 0.23193448781967163\n",
      "\n",
      "batch: 125, loss: 0.7196524143218994, pos_loss: 1.0895099639892578, neg_head_loss:0.45723050832748413, neg_tail_loss: 0.2423592209815979\n",
      "\n",
      "batch: 126, loss: 0.7082265019416809, pos_loss: 1.0684609413146973, neg_head_loss:0.4440033435821533, neg_tail_loss: 0.251980721950531\n",
      "\n",
      "batch: 127, loss: 0.6935383677482605, pos_loss: 1.0432822704315186, neg_head_loss:0.4356178939342499, neg_tail_loss: 0.2519710659980774\n",
      "\n",
      "batch: 128, loss: 0.7149097323417664, pos_loss: 1.0751328468322754, neg_head_loss:0.4564729630947113, neg_tail_loss: 0.2529003918170929\n",
      "\n",
      "batch: 129, loss: 0.7149040102958679, pos_loss: 1.0662150382995605, neg_head_loss:0.4710697829723358, neg_tail_loss: 0.2561161518096924\n",
      "\n",
      "batch: 130, loss: 0.6863210797309875, pos_loss: 1.0027751922607422, neg_head_loss:0.47049468755722046, neg_tail_loss: 0.2692391276359558\n",
      "\n",
      "batch: 131, loss: 0.6914339661598206, pos_loss: 1.0159859657287598, neg_head_loss:0.4796314835548401, neg_tail_loss: 0.25413259863853455\n",
      "\n",
      "batch: 132, loss: 0.6987500786781311, pos_loss: 1.0262129306793213, neg_head_loss:0.4540534019470215, neg_tail_loss: 0.2885209918022156\n",
      "\n",
      "batch: 133, loss: 0.6431856751441956, pos_loss: 0.9039955735206604, neg_head_loss:0.4964914619922638, neg_tail_loss: 0.26826006174087524\n",
      "\n",
      "batch: 134, loss: 0.6963817477226257, pos_loss: 1.0212467908859253, neg_head_loss:0.4536605477333069, neg_tail_loss: 0.2893727123737335\n",
      "\n",
      "batch: 135, loss: 0.686011791229248, pos_loss: 0.9966793060302734, neg_head_loss:0.47023409605026245, neg_tail_loss: 0.2804543972015381\n",
      "\n",
      "batch: 136, loss: 0.6848332285881042, pos_loss: 0.9871852993965149, neg_head_loss:0.47354453802108765, neg_tail_loss: 0.29141777753829956\n",
      "\n",
      "batch: 137, loss: 0.7003940343856812, pos_loss: 1.0236414670944214, neg_head_loss:0.45805877447128296, neg_tail_loss: 0.2962346076965332\n",
      "\n",
      "batch: 138, loss: 0.676609218120575, pos_loss: 0.97259521484375, neg_head_loss:0.4745200574398041, neg_tail_loss: 0.28672629594802856\n",
      "\n",
      "batch: 139, loss: 0.691253125667572, pos_loss: 1.0059787034988403, neg_head_loss:0.4611257314682007, neg_tail_loss: 0.2919294238090515\n",
      "\n",
      "batch: 140, loss: 0.6585214734077454, pos_loss: 0.9366693496704102, neg_head_loss:0.45618936419487, neg_tail_loss: 0.3045578598976135\n",
      "\n",
      "batch: 141, loss: 0.6646947860717773, pos_loss: 0.9487453699111938, neg_head_loss:0.47117412090301514, neg_tail_loss: 0.2901143729686737\n",
      "\n",
      "batch: 142, loss: 0.6802477240562439, pos_loss: 0.9805094003677368, neg_head_loss:0.4506487250328064, neg_tail_loss: 0.30932357907295227\n",
      "\n",
      "batch: 143, loss: 0.7127383947372437, pos_loss: 1.049317479133606, neg_head_loss:0.46309953927993774, neg_tail_loss: 0.2892189025878906\n",
      "\n",
      "batch: 144, loss: 0.6885421276092529, pos_loss: 1.002389669418335, neg_head_loss:0.44193023443222046, neg_tail_loss: 0.30745893716812134\n",
      "\n",
      "batch: 145, loss: 0.6715296506881714, pos_loss: 0.9699047207832336, neg_head_loss:0.43427661061286926, neg_tail_loss: 0.3120323419570923\n",
      "\n",
      "batch: 146, loss: 0.6326020359992981, pos_loss: 0.9007378816604614, neg_head_loss:0.42275869846343994, neg_tail_loss: 0.3061736226081848\n",
      "\n",
      "batch: 147, loss: 0.7147906422615051, pos_loss: 1.0735818147659302, neg_head_loss:0.4245709180831909, neg_tail_loss: 0.287428081035614\n",
      "\n",
      "batch: 148, loss: 0.6776297092437744, pos_loss: 0.9985095858573914, neg_head_loss:0.4144701063632965, neg_tail_loss: 0.299029678106308\n",
      "\n",
      "batch: 149, loss: 0.6824390292167664, pos_loss: 1.0193923711776733, neg_head_loss:0.39669105410575867, neg_tail_loss: 0.2942802906036377\n",
      "\n",
      "batch: 150, loss: 0.6741546392440796, pos_loss: 1.0088142156600952, neg_head_loss:0.3942965269088745, neg_tail_loss: 0.2846938371658325\n",
      "\n",
      "batch: 151, loss: 0.6992087960243225, pos_loss: 1.0638710260391235, neg_head_loss:0.39531058073043823, neg_tail_loss: 0.27378249168395996\n",
      "\n",
      "batch: 152, loss: 0.7229524850845337, pos_loss: 1.1128687858581543, neg_head_loss:0.3787532448768616, neg_tail_loss: 0.2873193025588989\n",
      "\n",
      "batch: 153, loss: 0.6734920740127563, pos_loss: 1.022918939590454, neg_head_loss:0.36886051297187805, neg_tail_loss: 0.27926990389823914\n",
      "\n",
      "batch: 154, loss: 0.7227141857147217, pos_loss: 1.1276617050170898, neg_head_loss:0.3616953194141388, neg_tail_loss: 0.27383798360824585\n",
      "\n",
      "batch: 155, loss: 0.6741670370101929, pos_loss: 1.0345299243927002, neg_head_loss:0.36136606335639954, neg_tail_loss: 0.2662423253059387\n",
      "\n",
      "batch: 156, loss: 0.6553258299827576, pos_loss: 0.9970347881317139, neg_head_loss:0.34819161891937256, neg_tail_loss: 0.27904194593429565\n",
      "\n",
      "batch: 157, loss: 0.6659026145935059, pos_loss: 1.0279322862625122, neg_head_loss:0.3397137522697449, neg_tail_loss: 0.2680320143699646\n",
      "\n",
      "batch: 158, loss: 0.6766229867935181, pos_loss: 1.0433683395385742, neg_head_loss:0.3505210280418396, neg_tail_loss: 0.26923421025276184\n",
      "\n",
      "batch: 159, loss: 0.7044130563735962, pos_loss: 1.1161967515945435, neg_head_loss:0.33000731468200684, neg_tail_loss: 0.255251407623291\n",
      "\n",
      "batch: 160, loss: 0.7084503173828125, pos_loss: 1.136183261871338, neg_head_loss:0.30660951137542725, neg_tail_loss: 0.2548251748085022\n",
      "\n",
      "batch: 161, loss: 0.70759117603302, pos_loss: 1.1357343196868896, neg_head_loss:0.3035178482532501, neg_tail_loss: 0.25537818670272827\n",
      "\n",
      "batch: 162, loss: 0.6879550218582153, pos_loss: 1.102117896080017, neg_head_loss:0.30568063259124756, neg_tail_loss: 0.24190382659435272\n",
      "\n",
      "batch: 163, loss: 0.6894259452819824, pos_loss: 1.1132872104644775, neg_head_loss:0.2957319915294647, neg_tail_loss: 0.2353973239660263\n",
      "\n",
      "batch: 164, loss: 0.7663733959197998, pos_loss: 1.2786409854888916, neg_head_loss:0.28269970417022705, neg_tail_loss: 0.2255120873451233\n",
      "\n",
      "batch: 165, loss: 0.7245177626609802, pos_loss: 1.197541356086731, neg_head_loss:0.28404340147972107, neg_tail_loss: 0.2189447283744812\n",
      "\n",
      "batch: 166, loss: 0.7133552432060242, pos_loss: 1.1781216859817505, neg_head_loss:0.2707175612449646, neg_tail_loss: 0.22646018862724304\n",
      "\n",
      "batch: 167, loss: 0.7377104163169861, pos_loss: 1.2372812032699585, neg_head_loss:0.2532925009727478, neg_tail_loss: 0.22298689186573029\n",
      "\n",
      "batch: 168, loss: 0.7220042943954468, pos_loss: 1.2133303880691528, neg_head_loss:0.24492621421813965, neg_tail_loss: 0.21643027663230896\n",
      "\n",
      "batch: 169, loss: 0.6502040028572083, pos_loss: 1.0738880634307861, neg_head_loss:0.2552306056022644, neg_tail_loss: 0.19780918955802917\n",
      "\n",
      "batch: 170, loss: 0.7348375916481018, pos_loss: 1.2534593343734741, neg_head_loss:0.23940789699554443, neg_tail_loss: 0.19302387535572052\n",
      "\n",
      "batch: 171, loss: 0.7375019788742065, pos_loss: 1.260702133178711, neg_head_loss:0.23771676421165466, neg_tail_loss: 0.19088709354400635\n",
      "\n",
      "batch: 172, loss: 0.7495274543762207, pos_loss: 1.2852777242660522, neg_head_loss:0.23812201619148254, neg_tail_loss: 0.18943247199058533\n",
      "\n",
      "batch: 173, loss: 0.7761008739471436, pos_loss: 1.3505890369415283, neg_head_loss:0.225626602768898, neg_tail_loss: 0.17759904265403748\n",
      "\n",
      "batch: 174, loss: 0.7374652028083801, pos_loss: 1.2800413370132446, neg_head_loss:0.21513110399246216, neg_tail_loss: 0.17464718222618103\n",
      "\n",
      "batch: 175, loss: 0.7835595011711121, pos_loss: 1.3809473514556885, neg_head_loss:0.2093134969472885, neg_tail_loss: 0.1630299985408783\n",
      "\n",
      "batch: 176, loss: 0.7094860672950745, pos_loss: 1.2257742881774902, neg_head_loss:0.21103261411190033, neg_tail_loss: 0.17536309361457825\n",
      "\n",
      "batch: 177, loss: 0.7035501599311829, pos_loss: 1.2202584743499756, neg_head_loss:0.2073303610086441, neg_tail_loss: 0.16635335981845856\n",
      "\n",
      "batch: 178, loss: 0.7895813584327698, pos_loss: 1.4030368328094482, neg_head_loss:0.19471630454063416, neg_tail_loss: 0.15753522515296936\n",
      "\n",
      "batch: 179, loss: 0.7131926417350769, pos_loss: 1.250077724456787, neg_head_loss:0.19241935014724731, neg_tail_loss: 0.16019576787948608\n",
      "\n",
      "batch: 180, loss: 0.756340742111206, pos_loss: 1.3361635208129883, neg_head_loss:0.19972370564937592, neg_tail_loss: 0.153312087059021\n",
      "\n",
      "batch: 181, loss: 0.70595782995224, pos_loss: 1.2382456064224243, neg_head_loss:0.19565267860889435, neg_tail_loss: 0.15168747305870056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch: 182, loss: 0.7767361402511597, pos_loss: 1.3851003646850586, neg_head_loss:0.19178801774978638, neg_tail_loss: 0.1449558436870575\n",
      "\n",
      "batch: 183, loss: 0.7466117143630981, pos_loss: 1.3283673524856567, neg_head_loss:0.18730565905570984, neg_tail_loss: 0.14240649342536926\n",
      "\n",
      "batch: 184, loss: 0.7418298721313477, pos_loss: 1.3163840770721436, neg_head_loss:0.1913452446460724, neg_tail_loss: 0.1432061493396759\n",
      "\n",
      "batch: 185, loss: 0.7542990446090698, pos_loss: 1.347132682800293, neg_head_loss:0.18823452293872833, neg_tail_loss: 0.13469618558883667\n",
      "\n",
      "batch: 186, loss: 0.7775257229804993, pos_loss: 1.395605206489563, neg_head_loss:0.18671472370624542, neg_tail_loss: 0.13217763602733612\n",
      "\n",
      "batch: 187, loss: 0.7536577582359314, pos_loss: 1.3469374179840088, neg_head_loss:0.18808545172214508, neg_tail_loss: 0.13267070055007935\n",
      "\n",
      "batch: 188, loss: 0.746329665184021, pos_loss: 1.3330820798873901, neg_head_loss:0.1862322986125946, neg_tail_loss: 0.13292212784290314\n",
      "\n",
      "batch: 189, loss: 0.7268615961074829, pos_loss: 1.3002578020095825, neg_head_loss:0.17830371856689453, neg_tail_loss: 0.12862706184387207\n",
      "\n",
      "batch: 190, loss: 0.7244231700897217, pos_loss: 1.292523741722107, neg_head_loss:0.18229037523269653, neg_tail_loss: 0.13035477697849274\n",
      "\n",
      "batch: 191, loss: 0.7666672468185425, pos_loss: 1.3795188665390015, neg_head_loss:0.1872347891330719, neg_tail_loss: 0.12039656192064285\n",
      "\n",
      "batch: 192, loss: 0.7263540625572205, pos_loss: 1.2973885536193848, neg_head_loss:0.1871911585330963, neg_tail_loss: 0.12344804406166077\n",
      "\n",
      "batch: 193, loss: 0.7717645764350891, pos_loss: 1.3905959129333496, neg_head_loss:0.18259942531585693, neg_tail_loss: 0.1232670247554779\n",
      "\n",
      "batch: 194, loss: 0.7377126216888428, pos_loss: 1.3252226114273071, neg_head_loss:0.18520815670490265, neg_tail_loss: 0.11519724130630493\n",
      "\n",
      "batch: 195, loss: 0.7302294373512268, pos_loss: 1.307494044303894, neg_head_loss:0.18674185872077942, neg_tail_loss: 0.1191878467798233\n",
      "\n",
      "batch: 196, loss: 0.7427067756652832, pos_loss: 1.3269122838974, neg_head_loss:0.20082513988018036, neg_tail_loss: 0.1161775216460228\n",
      "\n",
      "batch: 197, loss: 0.749345064163208, pos_loss: 1.3401637077331543, neg_head_loss:0.2037409543991089, neg_tail_loss: 0.1133117750287056\n",
      "\n",
      "batch: 198, loss: 0.7000713348388672, pos_loss: 1.2448714971542358, neg_head_loss:0.1903773993253708, neg_tail_loss: 0.12016499042510986\n",
      "\n",
      "batch: 199, loss: 0.7607409358024597, pos_loss: 1.3640583753585815, neg_head_loss:0.19753432273864746, neg_tail_loss: 0.1173127219080925\n",
      "\n",
      "batch: 200, loss: 0.7373600006103516, pos_loss: 1.3229992389678955, neg_head_loss:0.18945975601673126, neg_tail_loss: 0.11398183554410934\n",
      "\n",
      "batch: 201, loss: 0.718350887298584, pos_loss: 1.2839508056640625, neg_head_loss:0.1972939521074295, neg_tail_loss: 0.10820785909891129\n",
      "\n",
      "batch: 202, loss: 0.7398234009742737, pos_loss: 1.3190875053405762, neg_head_loss:0.21075743436813354, neg_tail_loss: 0.11036107689142227\n",
      "\n",
      "batch: 203, loss: 0.7031932473182678, pos_loss: 1.2532669305801392, neg_head_loss:0.19710904359817505, neg_tail_loss: 0.10913016647100449\n",
      "\n",
      "batch: 204, loss: 0.6664127707481384, pos_loss: 1.1715202331542969, neg_head_loss:0.21140454709529877, neg_tail_loss: 0.11120601743459702\n",
      "\n",
      "batch: 205, loss: 0.7315585017204285, pos_loss: 1.3067402839660645, neg_head_loss:0.19981150329113007, neg_tail_loss: 0.11294196546077728\n",
      "\n",
      "batch: 206, loss: 0.7090675830841064, pos_loss: 1.2618056535720825, neg_head_loss:0.2060992419719696, neg_tail_loss: 0.1065596491098404\n",
      "\n",
      "batch: 207, loss: 0.7270098924636841, pos_loss: 1.2970936298370361, neg_head_loss:0.20728254318237305, neg_tail_loss: 0.10656988620758057\n",
      "\n",
      "batch: 208, loss: 0.7380565404891968, pos_loss: 1.3228068351745605, neg_head_loss:0.19869019091129303, neg_tail_loss: 0.10792233049869537\n",
      "\n",
      "batch: 209, loss: 0.6650163531303406, pos_loss: 1.1728785037994385, neg_head_loss:0.19726437330245972, neg_tail_loss: 0.11704394221305847\n",
      "\n",
      "batch: 210, loss: 0.7273821830749512, pos_loss: 1.2986831665039062, neg_head_loss:0.20099541544914246, neg_tail_loss: 0.11116695404052734\n",
      "\n",
      "batch: 211, loss: 0.7053024172782898, pos_loss: 1.2586222887039185, neg_head_loss:0.19481909275054932, neg_tail_loss: 0.10914582759141922\n",
      "\n",
      "batch: 212, loss: 0.6890507936477661, pos_loss: 1.2181540727615356, neg_head_loss:0.21449610590934753, neg_tail_loss: 0.10539880394935608\n",
      "\n",
      "batch: 213, loss: 0.7126733660697937, pos_loss: 1.2684221267700195, neg_head_loss:0.20213022828102112, neg_tail_loss: 0.11171882599592209\n",
      "\n",
      "batch: 214, loss: 0.683168351650238, pos_loss: 1.210245966911316, neg_head_loss:0.2065509706735611, neg_tail_loss: 0.10563060641288757\n",
      "\n",
      "batch: 215, loss: 0.670099139213562, pos_loss: 1.1824637651443481, neg_head_loss:0.20434048771858215, neg_tail_loss: 0.1111285611987114\n",
      "\n",
      "batch: 216, loss: 0.661605954170227, pos_loss: 1.1691052913665771, neg_head_loss:0.19780106842517853, neg_tail_loss: 0.1104121059179306\n",
      "\n",
      "batch: 217, loss: 0.6792862415313721, pos_loss: 1.2025108337402344, neg_head_loss:0.20248736441135406, neg_tail_loss: 0.10963582247495651\n",
      "\n",
      "batch: 218, loss: 0.7318088412284851, pos_loss: 1.3062191009521484, neg_head_loss:0.20622891187667847, neg_tail_loss: 0.10856812447309494\n",
      "\n",
      "batch: 219, loss: 0.6520423293113708, pos_loss: 1.141832709312439, neg_head_loss:0.2138150930404663, neg_tail_loss: 0.11068882048130035\n",
      "\n",
      "batch: 220, loss: 0.7189199328422546, pos_loss: 1.2865115404129028, neg_head_loss:0.20214073359966278, neg_tail_loss: 0.10051601380109787\n",
      "\n",
      "batch: 221, loss: 0.6603379845619202, pos_loss: 1.1618214845657349, neg_head_loss:0.2078084796667099, neg_tail_loss: 0.10990048199892044\n",
      "\n",
      "batch: 222, loss: 0.6555117964744568, pos_loss: 1.158157467842102, neg_head_loss:0.1951761543750763, neg_tail_loss: 0.11055603623390198\n",
      "\n",
      "batch: 223, loss: 0.6958834528923035, pos_loss: 1.2399965524673462, neg_head_loss:0.18473832309246063, neg_tail_loss: 0.11880223453044891\n",
      "\n",
      "batch: 224, loss: 0.6766216158866882, pos_loss: 1.2028642892837524, neg_head_loss:0.19597017765045166, neg_tail_loss: 0.10478769242763519\n",
      "\n",
      "batch: 225, loss: 0.625076413154602, pos_loss: 1.0962291955947876, neg_head_loss:0.2005937695503235, neg_tail_loss: 0.10725361108779907\n",
      "\n",
      "batch: 226, loss: 0.6261829733848572, pos_loss: 1.1047734022140503, neg_head_loss:0.18762972950935364, neg_tail_loss: 0.10755538940429688\n",
      "\n",
      "batch: 227, loss: 0.6801435947418213, pos_loss: 1.2167350053787231, neg_head_loss:0.1823282390832901, neg_tail_loss: 0.10477615892887115\n",
      "\n",
      "batch: 228, loss: 0.6798359155654907, pos_loss: 1.2110464572906494, neg_head_loss:0.1861826479434967, neg_tail_loss: 0.11106815934181213\n",
      "\n",
      "batch: 229, loss: 0.7003712058067322, pos_loss: 1.2598310708999634, neg_head_loss:0.18126384913921356, neg_tail_loss: 0.10055901855230331\n",
      "\n",
      "batch: 230, loss: 0.700721263885498, pos_loss: 1.2611671686172485, neg_head_loss:0.17568236589431763, neg_tail_loss: 0.10486847907304764\n",
      "\n",
      "batch: 231, loss: 0.6694605350494385, pos_loss: 1.192779541015625, neg_head_loss:0.18549267947673798, neg_tail_loss: 0.10679048299789429\n",
      "\n",
      "batch: 232, loss: 0.6332927346229553, pos_loss: 1.128360390663147, neg_head_loss:0.17390626668930054, neg_tail_loss: 0.10254411399364471\n",
      "\n",
      "batch: 233, loss: 0.6999996304512024, pos_loss: 1.2617270946502686, neg_head_loss:0.17971646785736084, neg_tail_loss: 0.09682779014110565\n",
      "\n",
      "batch: 234, loss: 0.692238986492157, pos_loss: 1.2462068796157837, neg_head_loss:0.170207679271698, neg_tail_loss: 0.10633441060781479\n",
      "\n",
      "batch: 235, loss: 0.6431888341903687, pos_loss: 1.1511614322662354, neg_head_loss:0.17029711604118347, neg_tail_loss: 0.10013522952795029\n",
      "\n",
      "batch: 236, loss: 0.6242678165435791, pos_loss: 1.1145247220993042, neg_head_loss:0.16614052653312683, neg_tail_loss: 0.10188116133213043\n",
      "\n",
      "batch: 237, loss: 0.6729345321655273, pos_loss: 1.216972827911377, neg_head_loss:0.1590552181005478, neg_tail_loss: 0.09873713552951813\n",
      "\n",
      "batch: 238, loss: 0.6729394793510437, pos_loss: 1.2205817699432373, neg_head_loss:0.14926347136497498, neg_tail_loss: 0.10133100301027298\n",
      "\n",
      "batch: 239, loss: 0.649915337562561, pos_loss: 1.1727991104125977, neg_head_loss:0.15298298001289368, neg_tail_loss: 0.10108019411563873\n",
      "\n",
      "batch: 240, loss: 0.6588370203971863, pos_loss: 1.1951367855072021, neg_head_loss:0.15005838871002197, neg_tail_loss: 0.09501627087593079\n",
      "\n",
      "batch: 241, loss: 0.6665840148925781, pos_loss: 1.2087198495864868, neg_head_loss:0.15175023674964905, neg_tail_loss: 0.09714610874652863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch: 242, loss: 0.6669755578041077, pos_loss: 1.209039330482483, neg_head_loss:0.15471197664737701, neg_tail_loss: 0.0951116681098938\n",
      "\n",
      "batch: 243, loss: 0.6546593308448792, pos_loss: 1.1813890933990479, neg_head_loss:0.15573805570602417, neg_tail_loss: 0.10012094676494598\n",
      "\n",
      "batch: 244, loss: 0.6765038967132568, pos_loss: 1.2305793762207031, neg_head_loss:0.151437908411026, neg_tail_loss: 0.09341902285814285\n",
      "\n",
      "batch: 245, loss: 0.7000672221183777, pos_loss: 1.2844845056533813, neg_head_loss:0.14036500453948975, neg_tail_loss: 0.09093496203422546\n",
      "\n",
      "batch: 246, loss: 0.7012750506401062, pos_loss: 1.2887495756149292, neg_head_loss:0.13314883410930634, neg_tail_loss: 0.09445218741893768\n",
      "\n",
      "batch: 247, loss: 0.6161136627197266, pos_loss: 1.116081953048706, neg_head_loss:0.135354682803154, neg_tail_loss: 0.09693627059459686\n",
      "\n",
      "batch: 248, loss: 0.7013925313949585, pos_loss: 1.2919912338256836, neg_head_loss:0.1349545121192932, neg_tail_loss: 0.08663323521614075\n",
      "\n",
      "batch: 249, loss: 0.6372697353363037, pos_loss: 1.1629018783569336, neg_head_loss:0.13550466299057007, neg_tail_loss: 0.08777034282684326\n",
      "\n",
      "batch: 250, loss: 0.7007265090942383, pos_loss: 1.293136715888977, neg_head_loss:0.13191118836402893, neg_tail_loss: 0.0847216472029686\n",
      "\n",
      "batch: 251, loss: 0.683968186378479, pos_loss: 1.2645071744918823, neg_head_loss:0.12340329587459564, neg_tail_loss: 0.08345512300729752\n",
      "\n",
      "batch: 252, loss: 0.687502920627594, pos_loss: 1.2704071998596191, neg_head_loss:0.12971776723861694, neg_tail_loss: 0.07947952300310135\n",
      "\n",
      "batch: 253, loss: 0.6771053671836853, pos_loss: 1.2490370273590088, neg_head_loss:0.12432198226451874, neg_tail_loss: 0.08602553606033325\n",
      "\n",
      "batch: 254, loss: 0.7060354948043823, pos_loss: 1.3105192184448242, neg_head_loss:0.12431605160236359, neg_tail_loss: 0.07878728210926056\n",
      "\n",
      "batch: 255, loss: 0.6393080949783325, pos_loss: 1.1805917024612427, neg_head_loss:0.11842814087867737, neg_tail_loss: 0.07762094587087631\n",
      "\n",
      "batch: 256, loss: 0.6944575309753418, pos_loss: 1.290302038192749, neg_head_loss:0.11818359792232513, neg_tail_loss: 0.079042449593544\n",
      "\n",
      "batch: 257, loss: 0.7636764049530029, pos_loss: 1.431123971939087, neg_head_loss:0.11590170115232468, neg_tail_loss: 0.07655593007802963\n",
      "\n",
      "batch: 258, loss: 0.732353687286377, pos_loss: 1.3698673248291016, neg_head_loss:0.11561106145381927, neg_tail_loss: 0.07406898587942123\n",
      "\n",
      "batch: 259, loss: 0.7814871072769165, pos_loss: 1.4660738706588745, neg_head_loss:0.11718727648258209, neg_tail_loss: 0.07661353796720505\n",
      "\n",
      "batch: 260, loss: 0.6581827402114868, pos_loss: 1.2204002141952515, neg_head_loss:0.11577994376420975, neg_tail_loss: 0.07615047693252563\n",
      "\n",
      "batch: 261, loss: 0.7049732804298401, pos_loss: 1.315986156463623, neg_head_loss:0.10651885718107224, neg_tail_loss: 0.08140198886394501\n",
      "\n",
      "batch: 262, loss: 0.7447094321250916, pos_loss: 1.3980963230133057, neg_head_loss:0.10543200373649597, neg_tail_loss: 0.07721313834190369\n",
      "\n",
      "batch: 263, loss: 0.7092475891113281, pos_loss: 1.3286194801330566, neg_head_loss:0.10560362040996552, neg_tail_loss: 0.07414774596691132\n",
      "\n",
      "batch: 264, loss: 0.7105059623718262, pos_loss: 1.330536961555481, neg_head_loss:0.10941237956285477, neg_tail_loss: 0.07153753191232681\n",
      "\n",
      "batch: 265, loss: 0.7189034223556519, pos_loss: 1.345221757888794, neg_head_loss:0.11182286590337753, neg_tail_loss: 0.073347307741642\n",
      "\n",
      "epoch: 0, avg loss:0.6890230640432888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval metrics: defaultdict(<class 'float'>, {'MRR': 0.10395888808448048, 'MR': 1269.6559167379526, 'HITS@1': 0.05161106358711149, 'HITS@3': 0.11522668947818648, 'HITS@10': 0.1956658112346735})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|█████████████████████████████████| 1/1 [25:12<00:00, 1512.64s/Epoch]\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test metrics: defaultdict(<class 'float'>, {'MRR': 0.10042147524877144, 'MR': 1282.1407211961302, 'HITS@1': 0.04871494185478354, 'HITS@3': 0.11074464966285547, 'HITS@10': 0.1909508453044073})\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea27a291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237, 1000)\n",
      "(14541, 1000)\n"
     ]
    }
   ],
   "source": [
    "data_relation=np.load(os.path.join(MODEL_DIR, f'relation_embedding_{0}.npy'))\n",
    "print(data_relation.shape)             \n",
    "\n",
    "data_entity=np.load(os.path.join(MODEL_DIR, f'entity_embedding_{0}.npy'))        \n",
    "print(data_entity.shape)\n",
    "\n",
    "# train length 272115\n",
    "# eval length 17535\n",
    "# test length 20466\n",
    "\n",
    "# relations 237 \n",
    "# entities 14541 \n",
    "# hidden_dim 1000 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599cb405",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, optimizer, scheduler, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb955f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(model, test_data, num_entities, _num_negative_samples, _test_batch_size, all_data, 'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
